{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dinesh Asanka.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rz2fMuDLsX0xrrcF6Njf0STZ1uHNNyWU",
      "authorship_tag": "ABX9TyNXmGRBOUH3+oWXnWN9UTeq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinuraPunchihewa/Authorship-Identification-Language-Modelling/blob/main/word-language-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJVoke4pNj-g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e3d5b45-3049-4723-d8a3-e622c42b0ac7"
      },
      "source": [
        "!pip install textract"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting textract\n",
            "  Downloading https://files.pythonhosted.org/packages/32/31/ef9451e6e48a1a57e337c5f20d4ef58c1a13d91560d2574c738b1320bb8d/textract-1.6.3-py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/b7/34eec2fe5a49718944e215fde81288eec1fa04638aa3fb57c1c6cd0f98c3/beautifulsoup4-4.8.0-py3-none-any.whl (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 5.8MB/s \n",
            "\u001b[?25hCollecting python-pptx==0.6.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/86/eb979f7b0333ec769041aae36df8b9f1bd8bea5bbad44620663890dce561/python-pptx-0.6.18.tar.gz (8.9MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9MB 15.1MB/s \n",
            "\u001b[?25hCollecting six==1.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
            "Collecting EbookLib==0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/38/7d6ab2e569a9165249619d73b7bc6be0e713a899a3bc2513814b6598a84c/EbookLib-0.17.1.tar.gz (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 57.7MB/s \n",
            "\u001b[?25hCollecting SpeechRecognition==3.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e1/7f5678cd94ec1234269d23756dbdaa4c8cfaed973412f88ae8adf7893a50/SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8MB 86kB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.6/dist-packages (from textract) (3.0.4)\n",
            "Collecting docx2txt==0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/7d/60ee3f2b16d9bfdfa72e8599470a2c1a5b759cb113c6fe1006be28359327/docx2txt-0.8.tar.gz\n",
            "Collecting pdfminer.six==20181108\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/6e8746e6965d1a7ea8e97253e3d79e625da5547e8f376f88de5d024bacb9/pdfminer.six-20181108-py2.py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 56.3MB/s \n",
            "\u001b[?25hCollecting xlrd==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 61.5MB/s \n",
            "\u001b[?25hCollecting extract-msg==0.23.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/90/84485a914ed90adb5e87df17e626be04162fbba146dfecf34643659a4633/extract_msg-0.23.1-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[?25hCollecting argcomplete==1.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/4d/82/f44c9661e479207348a979b1f6f063625d11dc4ca6256af053719bbb0124/argcomplete-1.10.0-py2.py3-none-any.whl\n",
            "Collecting soupsieve>=1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from python-pptx==0.6.18->textract) (4.2.6)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from python-pptx==0.6.18->textract) (7.0.0)\n",
            "Collecting XlsxWriter>=0.5.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/98/17875723b6814fc4d0fc03f0997ee00de2dbd78cf195e2ec3f2c9c789d40/XlsxWriter-1.3.3-py2.py3-none-any.whl (144kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 57.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.6/dist-packages (from pdfminer.six==20181108->textract) (2.2.2)\n",
            "Collecting pycryptodome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/55/17fa0b55849dc135f7bc400993a9206bf06d1b5d9520b0bc8d47c57aaef5/pycryptodome-3.9.8-cp36-cp36m-manylinux1_x86_64.whl (13.7MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7MB 239kB/s \n",
            "\u001b[?25hCollecting olefile==0.46\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/81/e1ac43c6b45b4c5f8d9352396a14144bba52c8fec72a80f425f6a4d653ad/olefile-0.46.zip (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 63.9MB/s \n",
            "\u001b[?25hCollecting imapclient==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/39/e1c2c2c6e2356ab6ea81fcfc0a74b044b311d6a91a45300811d9a6077ef7/IMAPClient-2.1.0-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tzlocal==1.5.1 in /usr/local/lib/python3.6/dist-packages (from extract-msg==0.23.1->textract) (1.5.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from tzlocal==1.5.1->extract-msg==0.23.1->textract) (2018.9)\n",
            "Building wheels for collected packages: python-pptx, EbookLib, docx2txt, olefile\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-pptx: filename=python_pptx-0.6.18-cp36-none-any.whl size=275707 sha256=363a30faffb80398f7c71e868f8f7be0598b9e0511a8db4b79004a5067236278\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/1f/2c/29acca422b420a0b5210bd2cd7e9669804520d602d2462f20b\n",
            "  Building wheel for EbookLib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for EbookLib: filename=EbookLib-0.17.1-cp36-none-any.whl size=38163 sha256=1a104d52d4d6f644df1f0763b28db6e6c1c8da389069ddb0ebabbc44f3b0dccb\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/11/01/951369cbbf8f96878786a1f4da68bd7ac19a5d945b38e03d54\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-cp36-none-any.whl size=3965 sha256=4e71c8f36d1bd3e7216d2442f5c7adac39f5388025579b8e0d49fe7f455613f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/1f/26/a051209bbb77fc6bcfae2bb7e01fa0ff941b82292ab084d596\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.46-py2.py3-none-any.whl size=35415 sha256=abaee471c408cffdd366f9a500329bddc6f316d15f7477a33d9740bdaba0cb16\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/f4/11/bc4166107c27f07fd7bba707ffcb439619197638a1ac986df3\n",
            "Successfully built python-pptx EbookLib docx2txt olefile\n",
            "\u001b[31mERROR: nbclient 0.5.0 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.12.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: soupsieve, beautifulsoup4, XlsxWriter, python-pptx, six, EbookLib, SpeechRecognition, docx2txt, pycryptodome, pdfminer.six, xlrd, olefile, imapclient, extract-msg, argcomplete, textract\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Found existing installation: xlrd 1.1.0\n",
            "    Uninstalling xlrd-1.1.0:\n",
            "      Successfully uninstalled xlrd-1.1.0\n",
            "Successfully installed EbookLib-0.17.1 SpeechRecognition-3.8.1 XlsxWriter-1.3.3 argcomplete-1.10.0 beautifulsoup4-4.8.0 docx2txt-0.8 extract-msg-0.23.1 imapclient-2.1.0 olefile-0.46 pdfminer.six-20181108 pycryptodome-3.9.8 python-pptx-0.6.18 six-1.12.0 soupsieve-2.0.1 textract-1.6.3 xlrd-1.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0QgX8SMFYDl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d37d09d6-66b3-4b6f-fa75-b38be1f773af"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import textract\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNLKijoeFbjX"
      },
      "source": [
        "dinesh_asanka = textract.process('/content/drive/My Drive/Dinesh Asanka Train.docx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXgQTSGcFtoN"
      },
      "source": [
        "da_sentences = nltk.tokenize.sent_tokenize(dinesh_asanka.decode())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwmByhiAjZCW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcdbd671-0000-46f8-ffe3-907dc26debda"
      },
      "source": [
        "len(da_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1419"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jpeu_tDVF32_"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token = '<OOV>', filters='\\t\\n')\n",
        "tokenizer.fit_on_texts(da_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0BSInGMGASL"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlehR7tXGEzK"
      },
      "source": [
        "da_sequences = tokenizer.texts_to_sequences(da_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXwi0_DCZ9Q-"
      },
      "source": [
        "max_len = len(max(da_sequences, key=len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr2nQBxmGTLG"
      },
      "source": [
        "input_sequences = []\n",
        "for line in da_sentences:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(0, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    input_sequences.append(n_gram_sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd-iziHtLi8z"
      },
      "source": [
        "padded_sequences = pad_sequences(input_sequences, maxlen = max_len, padding = 'pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suiyat3gMRBr"
      },
      "source": [
        "inputs = padded_sequences[:, :-1]\n",
        "labels = padded_sequences[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzuamwKnMZAO"
      },
      "source": [
        "one_hot_encoded_labels = tf.keras.utils.to_categorical(labels, num_classes = total_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inju1grGSX18"
      },
      "source": [
        "tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Embedding(total_words, 64, input_length=inputs.shape[1]),\n",
        "                             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences = True)),\n",
        "                             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100)),\n",
        "                             tf.keras.layers.Dense(100, activation = 'relu'),\n",
        "                             tf.keras.layers.Dense(total_words, activation = 'softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EjT4ywJCmPF"
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTw-ez2wCtIM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f535e2b-091d-4b25-fd06-4f19faef9ae6"
      },
      "source": [
        "num_epochs = 100\n",
        "model.fit(inputs, one_hot_encoded_labels, epochs = num_epochs, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "725/725 - 137s - loss: 8.2436 - accuracy: 0.0112\n",
            "Epoch 2/100\n",
            "725/725 - 137s - loss: 7.8496 - accuracy: 0.0103\n",
            "Epoch 3/100\n",
            "725/725 - 137s - loss: 7.6451 - accuracy: 0.0147\n",
            "Epoch 4/100\n",
            "725/725 - 137s - loss: 7.4533 - accuracy: 0.0197\n",
            "Epoch 5/100\n",
            "725/725 - 137s - loss: 7.2703 - accuracy: 0.0226\n",
            "Epoch 6/100\n",
            "725/725 - 137s - loss: 7.1103 - accuracy: 0.0281\n",
            "Epoch 7/100\n",
            "725/725 - 137s - loss: 6.9520 - accuracy: 0.0344\n",
            "Epoch 8/100\n",
            "725/725 - 137s - loss: 6.8008 - accuracy: 0.0358\n",
            "Epoch 9/100\n",
            "725/725 - 137s - loss: 6.6501 - accuracy: 0.0394\n",
            "Epoch 10/100\n",
            "725/725 - 137s - loss: 6.5029 - accuracy: 0.0442\n",
            "Epoch 11/100\n",
            "725/725 - 137s - loss: 6.3580 - accuracy: 0.0472\n",
            "Epoch 12/100\n",
            "725/725 - 137s - loss: 6.2029 - accuracy: 0.0525\n",
            "Epoch 13/100\n",
            "725/725 - 137s - loss: 6.0511 - accuracy: 0.0572\n",
            "Epoch 14/100\n",
            "725/725 - 137s - loss: 5.9014 - accuracy: 0.0644\n",
            "Epoch 15/100\n",
            "725/725 - 138s - loss: 5.7480 - accuracy: 0.0710\n",
            "Epoch 16/100\n",
            "725/725 - 137s - loss: 5.5993 - accuracy: 0.0781\n",
            "Epoch 17/100\n",
            "725/725 - 138s - loss: 5.4503 - accuracy: 0.0832\n",
            "Epoch 18/100\n",
            "725/725 - 138s - loss: 5.2932 - accuracy: 0.0915\n",
            "Epoch 19/100\n",
            "725/725 - 138s - loss: 5.1308 - accuracy: 0.0981\n",
            "Epoch 20/100\n",
            "725/725 - 138s - loss: 4.9710 - accuracy: 0.1054\n",
            "Epoch 21/100\n",
            "725/725 - 137s - loss: 4.8134 - accuracy: 0.1165\n",
            "Epoch 22/100\n",
            "725/725 - 138s - loss: 4.6441 - accuracy: 0.1250\n",
            "Epoch 23/100\n",
            "725/725 - 137s - loss: 4.4879 - accuracy: 0.1387\n",
            "Epoch 24/100\n",
            "725/725 - 138s - loss: 4.3431 - accuracy: 0.1514\n",
            "Epoch 25/100\n",
            "725/725 - 137s - loss: 4.1952 - accuracy: 0.1637\n",
            "Epoch 26/100\n",
            "725/725 - 139s - loss: 4.0657 - accuracy: 0.1797\n",
            "Epoch 27/100\n",
            "725/725 - 138s - loss: 3.9284 - accuracy: 0.1975\n",
            "Epoch 28/100\n",
            "725/725 - 139s - loss: 3.8193 - accuracy: 0.2135\n",
            "Epoch 29/100\n",
            "725/725 - 139s - loss: 3.7025 - accuracy: 0.2266\n",
            "Epoch 30/100\n",
            "725/725 - 138s - loss: 3.5878 - accuracy: 0.2454\n",
            "Epoch 31/100\n",
            "725/725 - 139s - loss: 3.4819 - accuracy: 0.2595\n",
            "Epoch 32/100\n",
            "725/725 - 139s - loss: 3.3716 - accuracy: 0.2767\n",
            "Epoch 33/100\n",
            "725/725 - 140s - loss: 3.2782 - accuracy: 0.2931\n",
            "Epoch 34/100\n",
            "725/725 - 140s - loss: 3.1611 - accuracy: 0.3145\n",
            "Epoch 35/100\n",
            "725/725 - 140s - loss: 3.0561 - accuracy: 0.3310\n",
            "Epoch 36/100\n",
            "725/725 - 140s - loss: 2.9610 - accuracy: 0.3517\n",
            "Epoch 37/100\n",
            "725/725 - 140s - loss: 2.8539 - accuracy: 0.3658\n",
            "Epoch 38/100\n",
            "725/725 - 140s - loss: 2.7572 - accuracy: 0.3870\n",
            "Epoch 39/100\n",
            "725/725 - 140s - loss: 2.6537 - accuracy: 0.4080\n",
            "Epoch 40/100\n",
            "725/725 - 140s - loss: 2.5572 - accuracy: 0.4244\n",
            "Epoch 41/100\n",
            "725/725 - 141s - loss: 2.4595 - accuracy: 0.4478\n",
            "Epoch 42/100\n",
            "725/725 - 139s - loss: 2.3676 - accuracy: 0.4708\n",
            "Epoch 43/100\n",
            "725/725 - 139s - loss: 2.2750 - accuracy: 0.4874\n",
            "Epoch 44/100\n",
            "725/725 - 139s - loss: 2.1971 - accuracy: 0.5009\n",
            "Epoch 45/100\n",
            "725/725 - 139s - loss: 2.1026 - accuracy: 0.5267\n",
            "Epoch 46/100\n",
            "725/725 - 139s - loss: 2.0176 - accuracy: 0.5412\n",
            "Epoch 47/100\n",
            "725/725 - 139s - loss: 1.9473 - accuracy: 0.5601\n",
            "Epoch 48/100\n",
            "725/725 - 140s - loss: 1.8824 - accuracy: 0.5775\n",
            "Epoch 49/100\n",
            "725/725 - 139s - loss: 1.8093 - accuracy: 0.5931\n",
            "Epoch 50/100\n",
            "725/725 - 139s - loss: 1.7330 - accuracy: 0.6094\n",
            "Epoch 51/100\n",
            "725/725 - 139s - loss: 1.6700 - accuracy: 0.6253\n",
            "Epoch 52/100\n",
            "725/725 - 139s - loss: 1.6097 - accuracy: 0.6411\n",
            "Epoch 53/100\n",
            "725/725 - 139s - loss: 1.5583 - accuracy: 0.6500\n",
            "Epoch 54/100\n",
            "725/725 - 139s - loss: 1.5108 - accuracy: 0.6618\n",
            "Epoch 55/100\n",
            "725/725 - 139s - loss: 1.4496 - accuracy: 0.6761\n",
            "Epoch 56/100\n",
            "725/725 - 139s - loss: 1.3952 - accuracy: 0.6898\n",
            "Epoch 57/100\n",
            "725/725 - 139s - loss: 1.3568 - accuracy: 0.6973\n",
            "Epoch 58/100\n",
            "725/725 - 139s - loss: 1.3101 - accuracy: 0.7064\n",
            "Epoch 59/100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTVgo-lALaRr"
      },
      "source": [
        "def prepare_sentences(sentences):\n",
        "  input_sequences = []\n",
        "  for line in sentences:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(0, len(token_list)):\n",
        "      n_gram_sequence = token_list[:i+1]\n",
        "      input_sequences.append(n_gram_sequence)\n",
        "\n",
        "      padded_sequences = pad_sequences(input_sequences, maxlen = max_len, padding = 'pre')\n",
        "\n",
        "      inputs = padded_sequences[:, :-1]\n",
        "      labels = padded_sequences[:,-1]\n",
        "\n",
        "      one_hot_encoded_labels = tf.keras.utils.to_categorical(labels, num_classes = total_words)\n",
        "  return inputs, one_hot_encoded_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qtiil3jjuDl"
      },
      "source": [
        "aa_data = ['බෝරාවරුන් ඔවුන්ගේ වර්තමාන ආධ්‍යාත්මික නායකයා වූ 53 වන දායිවරයා, සායිද්නා මුෆාදල් ඉතා ගෞරවයෙන් සහ ආදරයෙන් අගය කරනවා.']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDo-wfzmj70I"
      },
      "source": [
        "aa_inputs, aa_labels = prepare_sentences(aa_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P48J5hEUj-6o"
      },
      "source": [
        "aa_probabilities = model.predict(aa_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCkT_zLbozWp"
      },
      "source": [
        "for i in range(0, aa_probabilities.shape[0] - 1):\n",
        "  print(str(i) + \" \" + str(np.sum(aa_probabilities[i] * aa_labels[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsazKHAsQCD1"
      },
      "source": [
        "lk_data = ['මෙසේ වෘත්තීය විෂයයන් ඔස්සේ කර්මාන්ත පුහුණුවක් ලබා ගැනීමෙන් පසුව රැකියාවකට පිවිසීමට හෝ ස්වයං රැකියාවක නිරත වීමට ශිෂ්‍යන්ට හැකියාව ලැබෙනවා.']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvTRSjUgQjzO"
      },
      "source": [
        "lk_inputs, lk_labels = prepare_sentences(lk_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ_VhQP-Qo8E"
      },
      "source": [
        "lk_probabilities = model.predict(lk_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B34GdRxdQuZZ"
      },
      "source": [
        "for i in range(0, lk_probabilities.shape[0] - 1):\n",
        "  print(str(i) + \" \" + str(np.sum(lk_probabilities[i] * lk_labels[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTVrX5nP3PCL"
      },
      "source": [
        "da_data = ['මේ චෝදනා රේගන් ජනාධිපතිවරයා මුළුමනින්ම ප්‍රතික්ෂේප කළත් මාධ්‍යයවලින් ආ පීඩනය නිසාම ටවර් කොමිසම පත්කළා.']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmj1ch2d3PCV"
      },
      "source": [
        "da_inputs, da_labels = prepare_sentences(da_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgsUTo5D3PCa"
      },
      "source": [
        "da_probabilities = model.predict(da_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgVR9z373PCg"
      },
      "source": [
        "for i in range(0, da_probabilities.shape[0] - 1):\n",
        "  print(str(i) + \" \" + str(np.sum(da_probabilities[i] * da_labels[i])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiNGvFOSQxeh"
      },
      "source": [
        "def calculate_probability(probabilities, labels):\n",
        "  log_prob_sentence = 0\n",
        "  for i in range(0, probabilities.shape[0] - 1):\n",
        "    log_prob_sentence += np.log(np.sum(probabilities[i] * labels[i]))\n",
        "\n",
        "  sentence_probability = np.exp(log_prob_sentence)\n",
        "  return log_prob_sentence"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}